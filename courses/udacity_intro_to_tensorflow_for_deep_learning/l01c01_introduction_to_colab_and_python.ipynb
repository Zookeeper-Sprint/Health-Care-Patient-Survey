{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sCqdC_4LDnGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import logging\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_logging(log_file):\n",
        "    \"\"\"Sets up logging configuration.\"\"\"\n",
        "    logging.basicConfig(\n",
        "        filename=log_file,\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        "    )\n",
        "\n",
        "def send_email(subject, body, to_email, from_email, smtp_server, smtp_port, smtp_user, smtp_password):\n",
        "    \"\"\"Sends an email notification.\"\"\"\n",
        "    # This function requires valid SMTP server details to work.\n",
        "    # It is included for completeness based on the original request, but can be skipped if email is not needed.\n",
        "    try:\n",
        "        msg = MIMEText(body)\n",
        "        msg[\"Subject\"] = subject\n",
        "        msg[\"From\"] = from_email\n",
        "        msg[\"To\"] = to_email\n",
        "\n",
        "        # print(\"Attempting to send email (requires valid SMTP config)...\")\n",
        "        # with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
        "        #     server.starttls()\n",
        "        #     server.login(smtp_user, smtp_password)\n",
        "        #     server.sendmail(from_email, to_email, msg.as_string())\n",
        "        logging.info(\"Email simulated successfully (SMTP disabled in sample).\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to send email: {e}\")\n",
        "\n",
        "def extract_table_and_operation(query):\n",
        "    \"\"\"\n",
        "    Extracts the operation type and likely table name using regex.\n",
        "    \"\"\"\n",
        "    patterns = {\n",
        "        \"rename_column\": r\"(?i)\\bALTER\\s+TABLE\\s+(`?\\\"?\\.?\\w+`?\\\"?).*?\\bRENAME\\s+COLUMN\\b\",\n",
        "        \"update\": r\"(?i)\\bUPDATE\\s+(`?\\\"?\\.?\\w+`?\\\"?)\\b\",\n",
        "        \"insert\": r\"(?i)\\bINSERT\\s+INTO\\s+(`?\\\"?\\.?\\w+`?\\\"?)\\b\",\n",
        "        \"delete\": r\"(?i)\\bDELETE\\s+FROM\\s+(`?\\\"?\\.?\\w+`?\\\"?)\\b\",\n",
        "    }\n",
        "\n",
        "    for operation, pattern in patterns.items():\n",
        "        match = re.search(pattern, query, re.DOTALL)\n",
        "        if match:\n",
        "            table_name = match.group(1).strip('`\"').replace('.', '_')\n",
        "            return operation, table_name\n",
        "\n",
        "    if re.search(r\"(?i)\\bSELECT\\b.*?\\bJOIN\\b\", query, re.DOTALL):\n",
        "        return \"join_queries\", \"multi_table\"\n",
        "\n",
        "    return \"other_queries\", \"unspecified\"\n",
        "\n",
        "def split_sql_file_by_table(input_file, base_output_dir, audit_file):\n",
        "    \"\"\"\n",
        "    Splits an SQL query document into folders structured by table and operation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        os.makedirs(base_output_dir, exist_ok=True)\n",
        "        with open(input_file, 'r') as file:\n",
        "            sql_queries = [q.strip() for q in file.read().split(';') if q.strip()]\n",
        "\n",
        "        audit_entries = []\n",
        "        for query in sql_queries:\n",
        "            operation, table_name = extract_table_and_operation(query)\n",
        "\n",
        "            if table_name and operation:\n",
        "                table_dir = os.path.join(base_output_dir, table_name)\n",
        "                os.makedirs(table_dir, exist_ok=True)\n",
        "\n",
        "                output_file_path = os.path.join(table_dir, f\"{operation}.sql\")\n",
        "\n",
        "                with open(output_file_path, 'a') as op_file:\n",
        "                    op_file.write(query + \";\\n\\n\")\n",
        "\n",
        "                log_message = f\"Appended query for table '{table_name}' ({operation}) to {output_file_path}\"\n",
        "                logging.info(log_message)\n",
        "                audit_entries.append(f\"{datetime.now()} - SUCCESS - {log_message}\")\n",
        "            else:\n",
        "                log_message = f\"Could not parse operation/table for query: {query[:50]}...\"\n",
        "                logging.warning(log_message)\n",
        "                audit_entries.append(f\"{datetime.now()} - WARNING - {log_message}\")\n",
        "\n",
        "        with open(audit_file, 'w') as audit:\n",
        "            audit.write(\"\\n\".join(audit_entries))\n",
        "        logging.info(\"Audit log written successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error occurred: {e}\")\n",
        "        raise\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    input_sql_file = \"queries.sql\"\n",
        "    output_directory = \"split_queries_by_table\"\n",
        "    log_file = \"process.log\"\n",
        "    audit_file = \"audit.log\"\n",
        "\n",
        "    # Placeholder Email Config (SMTP functionality is commented out in send_email)\n",
        "    email_config = {\n",
        "        \"to_email\": \"recipient@example.com\",\n",
        "        \"from_email\": \"sender@example.com\",\n",
        "        \"smtp_server\": \"smtp.example.com\",\n",
        "        \"smtp_port\": 587,\n",
        "        \"smtp_user\": \"smtp_user\",\n",
        "        \"smtp_password\": \"smtp_password\"\n",
        "    }\n",
        "\n",
        "    setup_logging(log_file)\n",
        "\n",
        "    try:\n",
        "        # Split SQL file\n",
        "        split_sql_file_by_table(input_sql_file, output_directory, audit_file)\n",
        "\n",
        "        # Send success email (simulation)\n",
        "        subject = \"SQL File Split - Success\"\n",
        "        body = f\"The SQL file has been successfully split. Check the audit log at {audit_file}.\"\n",
        "        send_email(subject, body, **email_config)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Send failure email (simulation)\n",
        "        subject = \"SQL File Split - Failure\"\n",
        "        body = f\"An error occurred during the SQL file split process: {e}\"\n",
        "        send_email(subject, body, **email_config)\n"
      ],
      "metadata": {
        "id": "c_hC0sPTDFlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Assuming 'spark' is an existing active SparkSession variable in your notebook environment\n",
        "\n",
        "# --- CONFIGURE THE PATH ---\n",
        "# This path is relative to where your notebook is running.\n",
        "# The previous script created this folder in the same directory as the notebook file.\n",
        "# We use 'file://' scheme for local file system access\n",
        "base_sql_path = \"file://./split_queries_by_table/\"\n",
        "\n",
        "print(f\"Searching for SQL files in: {base_sql_path}\")\n",
        "\n",
        "sql_files_to_process = []\n",
        "\n",
        "# os.walk iterates through the generated directory structure\n",
        "# Note: os.walk needs a standard local path, so we remove the 'file://' prefix for the walk itself.\n",
        "local_walk_path = base_sql_path.replace(\"file://\", \"\")\n",
        "for dirpath, _, filenames in os.walk(local_walk_path):\n",
        "    for f in filenames:\n",
        "        if f.endswith(\".sql\"):\n",
        "            full_path = os.path.join(dirpath, f)\n",
        "            sql_files_to_process.append(full_path)\n",
        "\n",
        "print(f\"Found {len(sql_files_to_process)} SQL files to execute.\")\n",
        "\n",
        "# Loop through and execute the SQL\n",
        "for local_file_path in sql_files_to_process:\n",
        "    # Read the content of the generated SQL file\n",
        "    with open(local_file_path, 'r') as f:\n",
        "        sql_query_content = f.read()\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nExecuting SQL from: {local_file_path}\")\n",
        "\n",
        "        # spark.sql() runs the query using your active Spark session\n",
        "        result_df = spark.sql(sql_query_content)\n",
        "\n",
        "        # Print a message depending on the type of operation\n",
        "        if 'SELECT' in sql_query_content.upper():\n",
        "             print(f\"-> Successfully loaded DataFrame. Result count: {result_df.count()}\")\n",
        "        else:\n",
        "             print(f\"-> Successfully executed DML operation (INSERT/UPDATE/DELETE/ALTER).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"-> FAILED to execute SQL from {local_file_path}: {e}\")\n"
      ],
      "metadata": {
        "id": "eXVVrY5ZEkvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l01c01_introduction_to_colab_and_python.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}